<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

	<title>bond0005/voice-enabled-interactive-learning @ GitHub</title>
	
	<style type="text/css">
		body {
  		margin-top: 1.0em;
  		background-color: #000000;
		  font-family: "Helvetica,Arial,FreeSans";
  		color: #ffffff;
    }
    #container {
      margin: 0 auto;
      width: 700px;
    }
		h1 { font-size: 3.8em; color: #ffffff; margin-bottom: 3px; }
		h1 .small { font-size: 0.4em; }
		h1 a { text-decoration: none }
		h2 { font-size: 1.5em; color: #ffffff; }
    h3 { text-align: center; color: #ffffff; }
    a { color: #ffffff; }
    .description { font-size: 1.2em; margin-bottom: 30px; margin-top: 30px; font-style: italic;}
    .download { float: right; }
		pre { background: #000; color: #fff; padding: 15px;}
    hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
    .footer { text-align:center; padding-top:30px; font-style: italic; }
	</style>
	
</head>

<body>
  <a href="http://github.com/bond0005/voice-enabled-interactive-learning"><img style="position: absolute; top: 0; right: 0; border: 0;" src="http://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub" /></a>

  <div id="container">

    <div class="download">
      <a href="http://github.com/bond0005/voice-enabled-interactive-learning/zipball/master">
        <img border="0" width="90" src="http://github.com/images/modules/download/zip.png"></a>
      <a href="http://github.com/bond0005/voice-enabled-interactive-learning/tarball/master">
        <img border="0" width="90" src="http://github.com/images/modules/download/tar.png"></a>
    </div>

    <h1><a href="http://github.com/bond0005/voice-enabled-interactive-learning">voice-enabled-interactive-learning</a>
      <span class="small">by <a href="http://github.com/bond0005">bond0005</a></span></h1>

    <div class="description">
      This project includes 3 parts:-

1:Speech Synthesis
2:Speech Recognition
3:Speech Analysis

1: Speech Synthesis:

In this part it takes text as input and voice as output.You can open any text file or doc file,it will read for u.

2: Speech Recognition:

In this part it takes speech as input and text as an ouput.Whatever you speak it will print on the screen.

3.Speech Analysis:

It has two parts 

a. waveform creation: In this part it record the speech and form the waveform of that speech.You can also save that file.

b. speech matching:In this part it matches two speech and give the output in percentage that how much that two speech     matches.

    </div>

    <p>
Have you ever talked to your computer and has it ever talked back to you? We mean, have you really, really talked to your computer? Where it actually recognized what you said and it spoke what you want? Does this sound impossible to you? Well, let us assure you that it is very much possible and you can do it if you have converted spoken input to text or text into speech. Speech recognition is thus sometimes referred to as speech-to-text, and speech synthesis is sometimes referred to as text-to-speech. 
Have you ever tried to learn a new language with a computer as a tutor? And have you ever checked your pronunciation? If you haven’t then you must go through this software.
Confused? So many questions and no answers? Don’t panic, we will answer all the above questions. Let us give you an overview of our project and answer to the above questions.

OVERVIEW

The idea of machines that speak and understand human speech has long been a fascination of application users and application builders. With advances in speech technology, this concept has now become a reality. Research projects have evolved and refined speech technology, making it feasible to develop applications that use speech technology to enhance the user's experience. 
There are two main speech technology concepts -- speech synthesis and speech recognition.
	Speech synthesis - Generating human speech from written text for a specific language. 
	Speech recognition - Converting human speech to words/commands. 
Together Speech Synthesis and Speech Recognition are called Speech Processing System.
Speech recognition allows you to provide input to an application with your voice. Just like clicking with your mouse, typing on your keyboard, or pressing a key on the phone keypad provides input to an application, speech recognition allows you to provide input by talking. In the desktop world, you need a microphone to be able to do this. 
Speech synthesis allows you to listen to your input text file. Just like clicking with your mouse, opening the document, and start reading. Speech synthesis provides you with the ability to listen to your documents while on the move. In the desktop world; you need speakers to be able to do this. 
Speech processing is an alternative to traditional methods of interacting with a computer, such as textual input through a keyboard and textual output on the screen. An effective system can replace, or reduce the reliability on, standard keyboard and mouse input and display output. This can especially assist the following:
	People who have little keyboard skills or experience, who are slow typists, or do not have the time or resources to develop keyboard skills.
	Dyslexic people or others who have problems with character or word use and manipulation in a textual form.
	People with physical disabilities that affect either their data entry, or ability to read (and therefore check) what they have entered.
A speech processing system consists of the following:
	A microphone, for the person to speak into.
	Speech recognition software.
	A computer to take and interpret the speech.
	Good quality soundcard/speakers for input and/or output.
For the past several decades, designers have processed speech for a wide variety of applications ranging from mobile communications to automatic reading machines. Speech recognition and speech synthesis reduce the overhead caused by alternate communication methods. Speech has not been used much in the field of electronics and computers due to the complexity and variety of speech signals and sounds. However, with modern processes, algorithms, and methods we can process speech signals easily and recognize the text. 
Speech is one of our most expedient and natural form of communication and so understandably it is a capability we would like AI system to process. 
The ability to communicate directly with programs offers several advantages. It eliminates the need of keyboard and speed up the interchange of information between user and system.

OBJECTIVES

In the fast moving world, if people lack something it is time. All are busy in their world. It will be welcomed if services are provided at their will.
	In the current system people generally interact with the system through the console input and console output. This causes a lot of wastage of time and manual overhead.
Another problem is of cost. Excessive usage of input and output devices can lead to their frequent degradation and replacement. This involves a lot of cost overhead.
	Another problem is Carpal Tunnel Syndrome. Many people don’t know the correct way of using a mouse and a keyboard. This syndrome is the result of this.
	Another problem is ineffective utilization of resources. While working on a single document, a user can not perform another task simultaneously. 
This product is a software program with a group of independent and interdependent functions and features that working together perform in unified way providing solutions to the above problems.
.Computer’s processing speed is much faster than a person’s typing speed, so to dictate to a person will take much more time as compared to dictating to a computer. And besides this advantage dictating to a computer frees the typist to do other chores.
Using the speech technology will reduce the usage of input and output devices, thereby reducing replacement frequency. In addition audio devices are inexpensive compared to console devices. Also, less usage of devices like keyboard and mouse will reduce the chances of various diseases.
The product provides a framework within which a user can intelligently, logically and systematically interact with the system reading and writing the documents and analyzing the speeches.
</p><h2>Dependencies</h2>
<p>Technology used:

This project is made in java.I used swing for the GUI purpose.Main speech engine used in this project are:
1.freetts
2.sphinx4
	
Grammer file is used for recognition purpose.

Software used:
1:Talking java SDK163
</p>
<h2>Install</h2>
<p>
HOW TO USE THIS PROJECT:

1.Firstly install talking java sdk163 with jre1.2
2.Set the classpath accorging to to you where you place this project in your computer.
3.High quality headphone shoud be used for clear voice.
4.Rum veil.bat file to run the project.
5.Click on synthesis button for speech synthesis.
6.Click on recognition button for speech recognition.
7.Click on analysis button for speech analysis.
	
You can add any word in grammer file which is stored in src folder.


</p>
<h2>Authors</h2>
<p>      AJAY KUMAR</p>
<h2>Contact</h2>
<p>AJAY KUMAR (ajay_20subhi@yahoo.co.in)<br/>      </p>


    <h2>Download</h2>
    <p>
      You can download this project in either
      <a href="http://github.com/bond0005/voice-enabled-interactive-learning/zipball/master">zip</a> or
      <a href="http://github.com/bond0005/voice-enabled-interactive-learning/tarball/master">tar</a> formats.
    </p>
    <p>You can also clone the project with <a href="http://git-scm.com">Git</a>
      by running:
      <pre>$ git clone git://github.com/bond0005/voice-enabled-interactive-learning</pre>
    </p>

    <div class="footer">
      get the source code on GitHub : <a href="http://github.com/bond0005/voice-enabled-interactive-learning">bond0005/voice-enabled-interactive-learning</a>
    </div>

  </div>

  <script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-0000007-7");
pageTracker._trackPageview();
} catch(err) {}</script>
</body>
</html>
