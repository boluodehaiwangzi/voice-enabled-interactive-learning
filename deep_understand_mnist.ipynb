{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_understand_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/boluodehaiwangzi/voice-enabled-interactive-learning/blob/gh-pages/deep_understand_mnist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "u9eP6piW8qrB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 整个MNITST 项目是分三个阶段进行的：\n",
        "## 1、简单的全连接神经网络模型，准确率可以达到92%\n",
        "## 2、全连接模型使用：relu，dropout，adam函数，准确率98%\n",
        "## 3、卷积神经网络 99.2%"
      ]
    },
    {
      "metadata": {
        "id": "OU8pdL-jWCyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1133
        },
        "outputId": "0632f2ad-53ae-44e7-c78e-eb800de5388a"
      },
      "cell_type": "code",
      "source": [
        "# 第一个项目，先实现传统的全连接神经网络\n",
        "\n",
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# 导入数据，并将数据转变到0,1之间\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "x_train,x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "# 定义模型的各个层\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512,activation=tf.nn.sigmoid),\n",
        "    tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "]\n",
        ")\n",
        "\n",
        "# 定义的优化器，损失函数\n",
        "model.compile(optimizer = 'adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# 训练\n",
        "model.fit(x_train, y_train,epochs=30)\n",
        "model.evaluate(x_test,y_test)\n",
        "\n",
        "\n",
        "# 结论：\n",
        "# 1、使用以上方式代码可以实现92.2%的准确率，对于SGD优化器来说，学习速度偏慢，所以需要迭代的次数也比较多，10次迭代还没收敛，需要25次才开始收敛\n",
        "# 2、在没有改变其他参数的情况下，仅仅改变优化器成adam，训练准确率可达99.99%，测试准确率98.2%"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.3398 - acc: 0.9033\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.1698 - acc: 0.9494\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.1124 - acc: 0.9665\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0783 - acc: 0.9765\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0568 - acc: 0.9835\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0423 - acc: 0.9872\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0316 - acc: 0.9909\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0236 - acc: 0.9933\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0174 - acc: 0.9954\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0131 - acc: 0.9970\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0096 - acc: 0.9977\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0075 - acc: 0.9983\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0057 - acc: 0.9989\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0043 - acc: 0.9992\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0037 - acc: 0.9993\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0032 - acc: 0.9992\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0024 - acc: 0.9995\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0012 - acc: 0.9999\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0027 - acc: 0.9993\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.0016 - acc: 0.9995\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0015 - acc: 0.9997\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 0.0016 - acc: 0.9996\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 5.0603e-04 - acc: 0.9999\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.0021 - acc: 0.9994\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 7.2210e-04 - acc: 0.9999\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 8.2525e-04 - acc: 0.9998\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 9.2212e-04 - acc: 0.9998\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 9s 145us/step - loss: 1.7875e-04 - acc: 1.0000\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 8s 142us/step - loss: 0.0019 - acc: 0.9995\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 3.9777e-04 - acc: 0.9999\n",
            "10000/10000 [==============================] - 0s 50us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07959315801936609, 0.9828]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "5Mu6SYFggtFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "39e9f183-ba85-4751-c240-4f2f3887a14e"
      },
      "cell_type": "code",
      "source": [
        "# 使用relu激活函数代替sigmoid函数，dropout，adam优化器\n",
        "\n",
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# 导入数据\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "# 定义模型\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "# 设定优化器,损失函数，输出结果方式\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# 训练\n",
        "model.fit(x_train,y_train,epochs=10)\n",
        "model.evaluate(x_test,y_test)\n",
        "\n",
        "# 总结：\n",
        "# 1、学习效果很好，五次训练就可以达到98.6%的效果，并在测试集上达到98%的效果\n",
        "# 2、adam优化器在训练集上，随着训练次数增加，训练集上的准确率会提升，但是测试集上的准确率不会\n",
        "# 3、adam优化器可能比较容易过拟合"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 9s 158us/step - loss: 0.2198 - acc: 0.9348\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0972 - acc: 0.9700\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0691 - acc: 0.9781\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0524 - acc: 0.9842\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0447 - acc: 0.9852\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0369 - acc: 0.9880\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.0321 - acc: 0.9892\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0256 - acc: 0.9915\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0254 - acc: 0.9914\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0220 - acc: 0.9927\n",
            "10000/10000 [==============================] - 1s 57us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07637497371167191, 0.9817]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "NDV1WMDsW-SS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "77c12197-2f26-420c-95cf-6ca1d2a1d6a5"
      },
      "cell_type": "code",
      "source": [
        "# 例程：类似VGG的卷积神经网络实现\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Generate dummy data\n",
        "x_train = np.random.random((100, 100, 100, 3))\n",
        "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
        "x_test = np.random.random((20, 100, 100, 3))\n",
        "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
        "\n",
        "model = Sequential()\n",
        "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
        "# this applies 32 convolution filters of size 3x3 each.\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
        "score = model.evaluate(x_test, y_test, batch_size=32)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 6s 65ms/step - loss: 2.3396\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 5s 55ms/step - loss: 2.2968\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 2.2581\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 2.2869\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 2.2851\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 2.2520\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 2.2467\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 2.2640\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 2.2236\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 5s 54ms/step - loss: 2.2424\n",
            "20/20 [==============================] - 0s 17ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hZXXYbwi9GPj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN MNIST实现"
      ]
    },
    {
      "metadata": {
        "id": "5DOaGYrT9EX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "3b3a02fa-0e51-4402-9f39-f8f63ce3b16f"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
        "x_train_tem, x_test_tem = x_train/255.0, x_test/255.0\n",
        "x_train = x_train_tem.reshape(60000,28,28,1)\n",
        "x_test = x_test_tem.reshape(10000,28,28,1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# 优化器，目标函数，输出形式\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# 训练\n",
        "model.fit(x_train,y_train,epochs=5)\n",
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 97s 2ms/step - loss: 0.1468 - acc: 0.9533\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0551 - acc: 0.9827\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 96s 2ms/step - loss: 0.0400 - acc: 0.9873\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0341 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0273 - acc: 0.9913\n",
            "10000/10000 [==============================] - 4s 434us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02310111620900716, 0.9925]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "W1l6a1hBNRUF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Epoch 1/5\n",
        "60000/60000 [==============================] - 97s 2ms/step - loss: 0.1468 - acc: 0.9533\n",
        "Epoch 2/5\n",
        "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0551 - acc: 0.9827\n",
        "Epoch 3/5\n",
        "60000/60000 [==============================] - 96s 2ms/step - loss: 0.0400 - acc: 0.9873\n",
        "Epoch 4/5\n",
        "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0341 - acc: 0.9894\n",
        "Epoch 5/5\n",
        "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0273 - acc: 0.9913\n",
        "10000/10000 [==============================] - 4s 434us/step\n",
        "[0.02310111620900716, 0.9925]"
      ]
    },
    {
      "metadata": {
        "id": "1QdEPsl79f0L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}